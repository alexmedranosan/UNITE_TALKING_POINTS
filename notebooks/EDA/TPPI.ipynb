{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "300f2022-d992-46fb-b96b-81430b889d2c",
   "metadata": {},
   "source": [
    "# TPPI: Talking Point Performance Index\n",
    "\n",
    "**Alejandro Medrano San Clemente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ac33cc0-64f3-42ff-b8a4-4821497e12b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TPPIResult(TypedDict):\n",
    "    TPPI: float\n",
    "    BertScore: float\n",
    "    Normalized_BertScore: float\n",
    "    Perplexity: float\n",
    "    Normalized_Perplexity: float\n",
    "    Flesch: float\n",
    "    Normalized_Flesch: float\n",
    "\n",
    "\n",
    "class TPPI:\n",
    "    def __init__(self, model_type: str = 'bert-base-uncased'):\n",
    "        \"\"\"\n",
    "        Inicializa el normalizador de puntuaciones y los modelos necesarios para los cálculos.\n",
    "        \"\"\"\n",
    "        self.scorer = BERTScorer(model_type=model_type)\n",
    "        self.gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "        self.gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_bert_score(bert_score: float) -> float:\n",
    "        \"\"\"\n",
    "        Normaliza el puntaje BERT en un rango de 0 a 1.\n",
    "        \"\"\"\n",
    "        return (bert_score + 1) / 2\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_perplexity(perplexity: float) -> float:\n",
    "        \"\"\"\n",
    "        Normaliza el valor de la perplejidad en un rango de 0 a 1.\n",
    "        \"\"\"\n",
    "        # Aseguramos que la perplexidad mínima sea al menos 1 para evitar división por cero\n",
    "        perplexity = max(perplexity, 1)\n",
    "        # Invertimos la fórmula para que valores bajos de perplexidad den valores altos normalizados\n",
    "        return 1 - (min(perplexity, 100) - 1) / 99\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_flesch(flesch: float) -> float:\n",
    "        \"\"\"\n",
    "        Normaliza el puntaje de Flesch en un rango de 0 a 1.\n",
    "        \"\"\"\n",
    "        return max(min(flesch, 100), 0) / 100\n",
    "\n",
    "    def calculate_bert_score(self, reference_text: str, generated_text: str) -> float:\n",
    "        \"\"\"\n",
    "        Calcula el BertScore entre un texto de referencia y uno generado.\n",
    "        \"\"\"\n",
    "        P, R, F1 = self.scorer.score([reference_text], [generated_text], verbose=False)\n",
    "        bert_score = F1.item()\n",
    "        return bert_score\n",
    "\n",
    "    def calculate_perplexity(self, text: str) -> float:\n",
    "        \"\"\"\n",
    "        Calcula la perplejidad de un texto utilizando el modelo GPT-2.\n",
    "        \"\"\"\n",
    "        encode = self.gpt2_tokenizer.encode(text, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            loss = self.gpt2_model(encode, labels=encode)[0]\n",
    "        perplexity = torch.exp(loss).item()\n",
    "        return perplexity\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_flesch(text: str) -> float:\n",
    "        \"\"\"\n",
    "        Calcula el puntaje de Flesch Reading Ease de un texto.\n",
    "        \"\"\"\n",
    "        flesch_score = flesch_reading_ease(text)\n",
    "        return flesch_score\n",
    "\n",
    "    def calculate_tppi(self, original_text: str, generated_text: str) -> TPPIResult:\n",
    "        \"\"\"\n",
    "        Calcula el TPPI basado en los textos de referencia y generados, devolviendo los puntajes de BERT,\n",
    "        perplejidad y Flesch tanto normalizados como sin normalizar.\n",
    "        \"\"\"\n",
    "        # Calcula BertScore\n",
    "        bert_score = self.calculate_bert_score(original_text, generated_text)\n",
    "        normalized_bert_score = self.normalize_bert_score(bert_score)\n",
    "\n",
    "        # Calcula Perplejidad\n",
    "        perplexity = self.calculate_perplexity(generated_text)\n",
    "        normalized_perplexity = self.normalize_perplexity(perplexity)\n",
    "\n",
    "        # Calcula Flesch\n",
    "        flesch = self.calculate_flesch(generated_text)\n",
    "        normalized_flesch = self.normalize_flesch(flesch)\n",
    "\n",
    "        # Calcula TPPI\n",
    "        tppi_score = 0.5 * normalized_bert_score + 0.25 * normalized_perplexity + 0.25 * normalized_flesch\n",
    "\n",
    "        # Devuelve todos los valores en un TypedDict\n",
    "        return TPPIResult(\n",
    "            TPPI=tppi_score,\n",
    "            BertScore=bert_score,\n",
    "            Normalized_BertScore=normalized_bert_score,\n",
    "            Perplexity=perplexity,\n",
    "            Normalized_Perplexity=normalized_perplexity,\n",
    "            Flesch=flesch,\n",
    "            Normalized_Flesch=normalized_flesch\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0bb4241-d102-42a1-906d-e0154bbb0894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro.medrano/.local/share/virtualenvs/UNITE_TALKING_POINTS-QWuKLflF/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tppi_calculator = TPPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13e0488a-abec-4bc9-82ab-524e2136ac07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TPPI': 0.8862211563825607,\n",
       " 'BertScore': 0.9112846255302429,\n",
       " 'Normalized_BertScore': 0.9556423127651215,\n",
       " 'Perplexity': 1019.5551147460938,\n",
       " 'Normalized_Perplexity': 1.0,\n",
       " 'Flesch': 63.36,\n",
       " 'Normalized_Flesch': 0.6335999999999999}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tppi_calculator.calculate_tppi(\"the courtyard of my house is particular\", \"the courtyard of my house sometimes is particular\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "753fef4e-c9ff-4590-9eb2-b36c95c64f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TPPI': 0.7683239503622055,\n",
       " 'BertScore': 0.402495801448822,\n",
       " 'Normalized_BertScore': 0.701247900724411,\n",
       " 'Perplexity': 164.62295532226562,\n",
       " 'Normalized_Perplexity': 1.0,\n",
       " 'Flesch': 67.08,\n",
       " 'Normalized_Flesch': 0.6708}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tppi_calculator.calculate_tppi(\n",
    "    \"the courtyard of my house is particular\",\n",
    "    \"The essence of the random text platypus, which has long been synonymous with Skype, is difficult to swimming pool or improve.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
