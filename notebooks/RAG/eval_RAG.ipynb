{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d8494d2-2c8a-4f97-8cb4-8a51095d7a31",
   "metadata": {},
   "source": [
    "# RAG evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9943b4-274f-4246-8813-e7008f56a581",
   "metadata": {},
   "source": [
    "# 0. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96917bf-af4d-431a-be2e-6612ca025202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textstat import flesch_reading_ease\n",
    "from bert_score import BERTScorer\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5df5a39-510e-4d9a-ba63-b9221346a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TPPIResult(TypedDict):\n",
    "    TPPI: float\n",
    "    BertScore: float\n",
    "    Normalized_BertScore: float\n",
    "    Perplexity: float\n",
    "    Normalized_Perplexity: float\n",
    "    Flesch: float\n",
    "    Normalized_Flesch: float\n",
    "\n",
    "\n",
    "class TPPI:\n",
    "    def __init__(self, model_type: str = 'bert-base-uncased'):\n",
    "        \"\"\"\n",
    "        Inicializa el normalizador de puntuaciones y los modelos necesarios para los cálculos.\n",
    "        \"\"\"\n",
    "        self.scorer = BERTScorer(model_type=model_type)\n",
    "        self.gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "        self.gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "        # Set the maximum lenght for GPT-2\n",
    "        self.perplexity_max_length = 1024\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_bert_score(bert_score: float) -> float:\n",
    "        \"\"\"\n",
    "        Normaliza el puntaje BERT en un rango de 0 a 1.\n",
    "        \"\"\"\n",
    "        return (bert_score + 1) / 2\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_perplexity(perplexity: float) -> float:\n",
    "        \"\"\"\n",
    "        Normaliza el valor de la perplejidad en un rango de 0 a 1.\n",
    "        \"\"\"\n",
    "        # Aseguramos que la perplexidad mínima sea al menos 1 para evitar división por cero\n",
    "        perplexity = max(perplexity, 1)\n",
    "        # Invertimos la fórmula para que valores bajos de perplexidad den valores altos normalizados\n",
    "        return 1 - (min(perplexity, 100) - 1) / 99\n",
    "\n",
    "    @staticmethod\n",
    "    def normalize_flesch(flesch: float) -> float:\n",
    "        \"\"\"\n",
    "        Normaliza el puntaje de Flesch en un rango de 0 a 1.\n",
    "        \"\"\"\n",
    "        return max(min(flesch, 100), 0) / 100\n",
    "\n",
    "    def calculate_bert_score(self, reference_text: str, generated_text: str) -> float:\n",
    "        \"\"\"\n",
    "        Calcula el BertScore entre un texto de referencia y uno generado.\n",
    "        \"\"\"\n",
    "        P, R, F1 = self.scorer.score([reference_text], [generated_text], verbose=False)\n",
    "        bert_score = F1.item()\n",
    "        return bert_score\n",
    "\n",
    "    def calculate_perplexity(self, text: str) -> float:\n",
    "        \"\"\"\n",
    "        Calcula la perplejidad de un texto utilizando el modelo GPT-2.\n",
    "        \"\"\"\n",
    "        # Tokenize the input text\n",
    "        encode = self.gpt2_tokenizer.encode(text, return_tensors='pt')\n",
    "    \n",
    "        # Trim the input if it exceeds the maximum length\n",
    "        if encode.size(1) > self.perplexity_max_length:  # Check the token sequence length\n",
    "            encode = encode[:, :self.perplexity_max_length]  # Trim to the first max_length tokens\n",
    "    \n",
    "        # Calculate the perplexity\n",
    "        with torch.no_grad():\n",
    "            loss = self.gpt2_model(encode, labels=encode)[0]\n",
    "        perplexity = torch.exp(loss).item()\n",
    "        \n",
    "        return perplexity\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_flesch(text: str) -> float:\n",
    "        \"\"\"\n",
    "        Calcula el puntaje de Flesch Reading Ease de un texto.\n",
    "        \"\"\"\n",
    "        flesch_score = flesch_reading_ease(text)\n",
    "        return flesch_score\n",
    "\n",
    "    def calculate_tppi(self, original_text: str, generated_text: str) -> TPPIResult:\n",
    "        \"\"\"\n",
    "        Calcula el TPPI basado en los textos de referencia y generados, devolviendo los puntajes de BERT,\n",
    "        perplejidad y Flesch tanto normalizados como sin normalizar.\n",
    "        \"\"\"\n",
    "        # Calcula BertScore\n",
    "        bert_score = self.calculate_bert_score(original_text, generated_text)\n",
    "        normalized_bert_score = self.normalize_bert_score(bert_score)\n",
    "\n",
    "        # Calcula Perplejidad\n",
    "        perplexity = self.calculate_perplexity(generated_text)\n",
    "        normalized_perplexity = self.normalize_perplexity(perplexity)\n",
    "\n",
    "        # Calcula Flesch\n",
    "        flesch = self.calculate_flesch(generated_text)\n",
    "        normalized_flesch = self.normalize_flesch(flesch)\n",
    "\n",
    "        # Calcula TPPI\n",
    "        tppi_score = 0.5 * normalized_bert_score + 0.25 * normalized_perplexity + 0.25 * normalized_flesch\n",
    "\n",
    "        # Devuelve todos los valores en un TypedDict\n",
    "        return TPPIResult(\n",
    "            TPPI=tppi_score,\n",
    "            BertScore=bert_score,\n",
    "            Normalized_BertScore=normalized_bert_score,\n",
    "            Perplexity=perplexity,\n",
    "            Normalized_Perplexity=normalized_perplexity,\n",
    "            Flesch=flesch,\n",
    "            Normalized_Flesch=normalized_flesch\n",
    "        )\n",
    "\n",
    "tppi = TPPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59afd2de-693a-4603-b4d3-19abb140ef06",
   "metadata": {},
   "source": [
    "## 1. Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb04362-db87-42e5-bc37-ee81e3bd5e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_exp = pd.read_csv('model_exp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9275c1-cc1e-4b64-b1b8-f7d1a04485fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632b8845-8d0c-4750-a795-ba8e75c58be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatura_exp = pd.read_csv('temperature_exp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0997a3b5-bcdd-46ce-af74-0a81fe20efb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatura_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee31b25b-dc4a-4f1e-ae09-920958d7e285",
   "metadata": {},
   "source": [
    "## 2. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f62707-7204-4608-8c33-3a85ebceae7b",
   "metadata": {},
   "source": [
    "### 2.1 Model experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364422c2-9734-481b-ac73-ea055b390039",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = model_exp.apply(lambda row: tppi.calculate_tppi(row['content'], row['generated_doc']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d94fe1a-920b-4063-b3b9-62e879bdcd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.concat([model_exp, pd.DataFrame(all_results.to_list())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d22da1-9e8f-4ff7-93dc-5c4f982b77e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula estadísticas básicas para cada método\n",
    "statistics = all_results.groupby('model').agg({\n",
    "    'TPPI': ['mean', 'std', 'min', 'max'],\n",
    "    'BertScore': ['mean'],\n",
    "    'Perplexity': ['mean'],\n",
    "    'Flesch' : ['mean']\n",
    "}).reset_index()\n",
    "\n",
    "print(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7b5fd7-b704-45d9-b089-0028d9070ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los nombres de las métricas para iterar\n",
    "metrics = ['TPPI', 'Normalized_BertScore', 'Normalized_Perplexity', 'Normalized_Flesch']\n",
    "\n",
    "# Crear un subplot 2x2 para los boxplots de cada métrica\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 12))\n",
    "fig.suptitle('Distribución de Métricas por Método de Vectorización', fontsize=16)\n",
    "\n",
    "# Iterar sobre las métricas y los ejes para crear los boxplots\n",
    "for ax, metric in zip(axes.flatten(), metrics):\n",
    "    all_results.boxplot(column=metric, by='model', ax=ax, grid=False)\n",
    "    ax.set_title(metric)\n",
    "    ax.set_xlabel('Modelo')\n",
    "    ax.set_ylim(0, 1)  # Asegurar que el gráfico esté limitado entre 0 y 1\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45)  # Rotar las etiquetas para mejor legibilidad\n",
    "\n",
    "# Ajustar el layout para evitar la superposición de los títulos y etiquetas\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Ajusta los límites del rectángulo del layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56851b86-631c-4de4-afbc-4af3bed1fba7",
   "metadata": {},
   "source": [
    "### 2.2 Temperature experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2829d2a-6883-4348-bc8d-24492c914f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = temperatura_exp.apply(lambda row: tppi.calculate_tppi(row['content'], row['generated_doc']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99da8522-6683-4f65-995a-e66fc1965733",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.concat([temperatura_exp, pd.DataFrame(all_results.to_list())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12d823b-dcb5-4be6-aa18-8a5a4128d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula estadísticas básicas para cada método\n",
    "statistics = all_results.groupby('temperature').agg({\n",
    "    'TPPI': ['mean', 'std', 'min', 'max'],\n",
    "    'BertScore': ['mean'],\n",
    "    'Perplexity': ['mean'],\n",
    "    'Flesch' : ['mean']\n",
    "}).reset_index()\n",
    "\n",
    "print(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c945c5de-f60a-41ef-ac12-46b4138a5411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating mean values for each 'n'\n",
    "mean_values = all_results[['TPPI', 'Normalized_BertScore', 'Normalized_Perplexity', 'Normalized_Flesch', 'temperature']].groupby('temperature').mean().reset_index()\n",
    "# Generating error bars (standard deviation as an example)\n",
    "std_values = all_results[['TPPI', 'Normalized_BertScore', 'Normalized_Perplexity', 'Normalized_Flesch', 'temperature']].groupby('temperature').std().reset_index()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.errorbar(mean_values['temperature'], mean_values['TPPI'], yerr=std_values['TPPI'], marker='o', label='Mean TPPI', capsize=5)\n",
    "plt.errorbar(mean_values['temperature'], mean_values['Normalized_BertScore'], yerr=std_values['Normalized_BertScore'], marker='o', label='Mean Normalized BertScore', capsize=5)\n",
    "plt.errorbar(mean_values['temperature'], mean_values['Normalized_Perplexity'], yerr=std_values['Normalized_Perplexity'], marker='o', label='Mean Normalized Perplexity', capsize=5)\n",
    "plt.errorbar(mean_values['temperature'], mean_values['Normalized_Flesch'], yerr=std_values['Normalized_Flesch'], marker='o', label='Mean Normalized Flesch', capsize=5)\n",
    "\n",
    "plt.title('TPPI and métricas normalizadas vs. temperatura')\n",
    "plt.xlabel('Temperature')\n",
    "plt.ylabel('Puntuación')\n",
    "plt.xticks(mean_values['temperature'])  # Ensure x-axis labels match the temperature values\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d586cb-5ce4-48ed-b35d-c908fec75289",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
